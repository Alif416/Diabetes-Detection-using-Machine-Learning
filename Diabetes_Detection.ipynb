{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMx9DRwI68Y7GRC29l9aTqZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alif416/Diabetes-Detection-using-Machine-Learning/blob/main/Diabetes_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2x_-42T7S6gN"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv(\"/content/diabetes_dataset.csv\")\n",
        "dataset.head(200)\n"
      ],
      "metadata": {
        "id": "Nr2NRkcRb3ln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_data = dataset.select_dtypes(include='number')\n",
        "\n",
        "#append the features of numerical_data to list\n",
        "numerical_features=numerical_data.columns.tolist()\n",
        "\n",
        "print(f'There are {len(numerical_features)} numerical features:', '\\n')\n",
        "print(numerical_features)"
      ],
      "metadata": {
        "id": "qSdz4jKr8Dqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Selecting categoricalfeatures\n",
        "categorical_data=dataset.select_dtypes(include= 'object')\n",
        "\n",
        "#append the features of categorical_data to list\n",
        "categorical_features=categorical_data.columns.tolist()\n",
        "\n",
        "print(f'There are {len(categorical_features)} numerical features:', '\\n')\n",
        "print(categorical_features)"
      ],
      "metadata": {
        "id": "ybEXxxgK8L2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Correlation Analysis And HeatMap**"
      ],
      "metadata": {
        "id": "EdwOK5KTD5Fc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the correlation matrix\n",
        "correlation_matrix = numerical_data.corr()\n",
        "correlation_matrix"
      ],
      "metadata": {
        "id": "PaRLQ-29D9UN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.3f', linewidths=0.3)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-Tkl8wlfEIM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Check Whether Imbalance Or Not**"
      ],
      "metadata": {
        "id": "8NcL92r09hbz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#check Imbalance in data\n",
        "\n",
        "#group instances based on the classes in OUTCOME variable\n",
        "class_counts=dataset.groupby(\"diabetes\").size()\n",
        "\n",
        "columns=['outcome','count','percentage']\n",
        "outcome=[0,1]\n",
        "count=list()\n",
        "percentage=list()\n",
        "\n",
        "#Calculate the percentage of each value of the OUTCOME variable from total\n",
        "for val in range(2):\n",
        "    count.append(class_counts[val])\n",
        "    percent=(class_counts[val]/105000)*100\n",
        "    percentage.append(percent)\n",
        "\n",
        "# Convert the calulated values into a dataframe\n",
        "imbalance_df=pd.DataFrame(list(zip(outcome,count,percentage)),columns=columns)\n",
        "imbalance_df\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ch0jSJ8YEkk7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load your dataset\n",
        "# df = pd.read_csv(\"your_dataset.csv\")  # Uncomment and modify this if loading from a CSV\n",
        "\n",
        "# Extract the target column\n",
        "y = dataset['diabetes']  # Replace 'diabetes' with the actual column name if different\n",
        "\n",
        "# Count occurrences of each class\n",
        "class_counts = y.value_counts().sort_index()\n",
        "\n",
        "# Plot bar chart\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar(class_counts.index.astype(str), class_counts.values, color=['blue', 'red'])  # Convert index to string for labels\n",
        "plt.xlabel(\"Class (Diabetes: 0 = No, 1 = Yes)\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Class Distribution in Dataset\")\n",
        "plt.xticks([0, 1], ['No Diabetes (0)', 'Diabetes (1)'])  # Optional: better labeling\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Hf8NNN45FPI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.isnull().sum()"
      ],
      "metadata": {
        "id": "e8pzk8FaF6gM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **EDA**"
      ],
      "metadata": {
        "id": "8ikE1W2tAUcV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_data.hist(figsize=(12,12),bins=20)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IH9Y-RXh_Njq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Select only numerical columns for boxplot analysis\n",
        "numeric_cols = dataset.select_dtypes(include=['int64', 'float64']).columns\n",
        "\n",
        "# Set up the figure\n",
        "plt.figure(figsize=(20, 30))\n",
        "\n",
        "# Plot boxplots for each numerical feature including the target variable 'OUTCOME'\n",
        "for i, col in enumerate(numeric_cols, 1):\n",
        "    plt.subplot(len(numeric_cols), 1, i)\n",
        "    sns.boxplot(x=dataset[col], color='skyblue')\n",
        "    plt.title(f'Boxplot of {col}', fontsize=12)\n",
        "    plt.tight_layout()\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "mmNsixYQA2Nt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Pre-Processing**"
      ],
      "metadata": {
        "id": "fJfUCWTbBf3o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_data.isnull().sum()"
      ],
      "metadata": {
        "id": "33HLJ4FvCRvH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_data.isnull().sum()"
      ],
      "metadata": {
        "id": "NTybdUHhDYHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Missing Values  both are existing in the num data and cat data\n",
        "#Con: You may lose important features that are strongly related to the target (like bmi, gender, or HbA1c_level).\n",
        "#Con: You lose valuable data, especially if the dataset is not very large.\n",
        "\n",
        "#If many rows have missing values, dropping them reduces your dataset size and may hurt model performance.\n",
        "\n",
        "\"\"\"Keeps all rows and columns â€” preserves your dataset size and structure.\n",
        "\n",
        "If done correctly (median for numbers, mode for categories), it minimizes distortion.\n",
        "\n",
        "Prepares your data for ML without losing important signals.\"\"\""
      ],
      "metadata": {
        "id": "3GUlsH43DeGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# List of binary columns to impute\n",
        "binary_cols = ['diabetes', 'hypertension', 'heart_disease']\n",
        "\n",
        "# Apply mode imputation (fills missing values with the most frequent class)\n",
        "imputer = SimpleImputer(strategy='most_frequent')\n",
        "numerical_data[binary_cols] = imputer.fit_transform(numerical_data[binary_cols])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vEGo64vuD6M0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Select columns for imputation\n",
        "num_cols = ['bmi', 'HbA1c_level', 'blood_glucose_level', 'age']\n",
        "\n",
        "# Use Median Imputation (recommended for skewed data)\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "numerical_data[num_cols] = imputer.fit_transform(numerical_data[num_cols])\n",
        "\n",
        "print(numerical_data[num_cols].isnull().sum())  # Verify missing values are removed"
      ],
      "metadata": {
        "id": "p1gLIKGAjEXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_data.isnull().sum()"
      ],
      "metadata": {
        "id": "t3LtgBafFPk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Use mode imputation to fill missing gender values\n",
        "imputer = SimpleImputer(strategy='most_frequent')\n",
        "categorical_data[['gender']] = imputer.fit_transform(categorical_data[['gender']])\n",
        "\n",
        "# Verify that missing values are removed\n",
        "print(categorical_data['gender'].isnull().sum())  # Should be 0\n",
        "\n"
      ],
      "metadata": {
        "id": "2MQco7wAGUrM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_data"
      ],
      "metadata": {
        "id": "PAJNo4kEq-__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_data['smoking_history'].fillna(categorical_data['smoking_history'].mode()[0], inplace=True)"
      ],
      "metadata": {
        "id": "HlmebdZlXsCr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_data.isnull().sum()"
      ],
      "metadata": {
        "id": "iq6YnJvSGeHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Encoding**"
      ],
      "metadata": {
        "id": "S0yYzonuJHhd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_data['gender'] = categorical_data['gender'].map({'Male': 0, 'Female': 1})"
      ],
      "metadata": {
        "id": "37_eoJ06BjOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_data"
      ],
      "metadata": {
        "id": "SedNRltgtK6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "categorical_data['smoking_history'] = encoder.fit_transform(categorical_data['smoking_history'])  # Encodes categories as numbers\n",
        "print(categorical_data['smoking_history'].unique())  # Check numeric encoding"
      ],
      "metadata": {
        "id": "G1cL123MGVQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_data.columns"
      ],
      "metadata": {
        "id": "Mvn4iRmZowoY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "kLYrjLcI5Ibx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_df = pd.concat([numerical_data, categorical_data], axis=1)\n",
        "print(final_df)"
      ],
      "metadata": {
        "id": "7IoMOVRlS9kI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df\n"
      ],
      "metadata": {
        "id": "qeXJpQwOTW0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df.columns"
      ],
      "metadata": {
        "id": "MUhqVSSKdP-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature Scaling**"
      ],
      "metadata": {
        "id": "5B5KcPXXOiBy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0YH_SHeFShKM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "num_cols = ['age', 'bmi', 'HbA1c_level', 'blood_glucose_level']\n",
        "\n",
        "final_df[num_cols] = scaler.fit_transform(final_df[num_cols])\n"
      ],
      "metadata": {
        "id": "M4Gy5QvcOqxf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df"
      ],
      "metadata": {
        "id": "tGfgijAqk3R7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define input features (X) and target column (y)\n",
        "target_col = 'diabetes'  # Change to your actual target variable\n",
        "X = final_df.drop(columns=[target_col])  # Exclude target from features\n",
        "y = final_df[target_col]  # Target variable\n",
        "\n",
        "# Perform stratified train-test split (70% train, 30% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "# Verify class distribution remains similar\n",
        "print(\"Training set class distribution:\\n\", y_train.value_counts(normalize=True))\n",
        "print(\"Test set class distribution:\\n\", y_test.value_counts(normalize=True))"
      ],
      "metadata": {
        "id": "LzN6BOI_lMg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "imputer = SimpleImputer(strategy='most_frequent')\n",
        "final_df[['gender']] = imputer.fit_transform(final_df[['gender']])\n"
      ],
      "metadata": {
        "id": "e8vOKZ9tuKYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report"
      ],
      "metadata": {
        "id": "hZLcijjhm1lR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_col = 'diabetes'\n",
        "X = final_df.drop(columns=[target_col])  # Features\n",
        "y = final_df[target_col]  # Target variable\n",
        "\n",
        "# Perform Stratified Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)"
      ],
      "metadata": {
        "id": "F2CGmz0Tm5dJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df.isnull().sum()"
      ],
      "metadata": {
        "id": "VqjdbP3hnQpK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)  # Use the same scaler for test data"
      ],
      "metadata": {
        "id": "DNLo3H6DnCDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Logistic_regression**"
      ],
      "metadata": {
        "id": "8Ri0CQ5RvHdc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "log_reg = LogisticRegression()\n",
        "log_reg.fit(X_train, y_train)\n",
        "y_pred_log = log_reg.predict(X_test)\n",
        "\n",
        "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred_log))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_log))"
      ],
      "metadata": {
        "id": "N55uS2B7nDM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **KNN**"
      ],
      "metadata": {
        "id": "uIa9xCaPvOQA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=5)  # You can tune 'n_neighbors' later\n",
        "knn.fit(X_train, y_train)\n",
        "y_pred_knn = knn.predict(X_test)\n",
        "\n",
        "print(\"KNN Accuracy:\", accuracy_score(y_test, y_pred_knn))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_knn))"
      ],
      "metadata": {
        "id": "ujwc6NaKu2Ud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Neural Network**"
      ],
      "metadata": {
        "id": "fqGqUNLZvr0s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp = MLPClassifier(hidden_layer_sizes=(64, 32), max_iter=500, random_state=42)  # Tunable parameters\n",
        "mlp.fit(X_train, y_train)\n",
        "y_pred_mlp = mlp.predict(X_test)\n",
        "\n",
        "print(\"Neural Network Accuracy:\", accuracy_score(y_test, y_pred_mlp))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_mlp))"
      ],
      "metadata": {
        "id": "NfIyqkQ1vRJc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Bar Chart: Prediction Accuracy of All Models**"
      ],
      "metadata": {
        "id": "JHU9_qSSwHr9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Store model names and accuracy scores\n",
        "models = ['Logistic Regression', 'KNN', 'Neural Network']\n",
        "accuracies = [accuracy_score(y_test, y_pred_log), accuracy_score(y_test, y_pred_knn), accuracy_score(y_test, y_pred_mlp)]\n",
        "\n",
        "# Create bar plot\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar(models, accuracies, color=['blue', 'red', 'green'])\n",
        "plt.xlabel(\"Models\")\n",
        "plt.ylabel(\"Accuracy Score\")\n",
        "plt.title(\"Model Accuracy Comparison\")\n",
        "plt.ylim(0, 1)  # Accuracy ranges between 0 and 1\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Abnk172FwGbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ** Precision, Recall Comparison of Each Model**"
      ],
      "metadata": {
        "id": "k1woqM5lwSO0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "# Compute precision and recall\n",
        "precision_log = precision_score(y_test, y_pred_log)\n",
        "recall_log = recall_score(y_test, y_pred_log)\n",
        "\n",
        "precision_knn = precision_score(y_test, y_pred_knn)\n",
        "recall_knn = recall_score(y_test, y_pred_knn)\n",
        "\n",
        "precision_mlp = precision_score(y_test, y_pred_mlp)\n",
        "recall_mlp = recall_score(y_test, y_pred_mlp)\n",
        "\n",
        "# Print results\n",
        "print(f\"Logistic Regression - Precision: {precision_log}, Recall: {recall_log}\")\n",
        "print(f\"KNN - Precision: {precision_knn}, Recall: {recall_knn}\")\n",
        "print(f\"Neural Network - Precision: {precision_mlp}, Recall: {recall_mlp}\")"
      ],
      "metadata": {
        "id": "30gBnnf9wYHV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Confusion Matrix for Each Model**"
      ],
      "metadata": {
        "id": "OAanUkguweHN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "# Define models and predictions\n",
        "model_preds = {'Logistic Regression': y_pred_log, 'KNN': y_pred_knn, 'Neural Network': y_pred_mlp}\n",
        "\n",
        "for model_name, preds in model_preds.items():\n",
        "    cm = confusion_matrix(y_test, preds)\n",
        "    plt.figure(figsize=(5, 4))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "    plt.title(f'Confusion Matrix - {model_name}')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "u-_6veLEwjuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **AUC Score & ROC Curve**"
      ],
      "metadata": {
        "id": "Ynm04x7ywy4C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "# Compute ROC curves\n",
        "models = {'Logistic Regression': y_pred_log, 'KNN': y_pred_knn, 'Neural Network': y_pred_mlp}\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "for model_name, preds in models.items():\n",
        "    fpr, tpr, _ = roc_curve(y_test, preds)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.plot(fpr, tpr, label=f'{model_name} (AUC = {roc_auc:.2f})')\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'r--')  # Diagonal line\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve Comparison')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cH_6IER3wuEs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}